{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNVFhtb8bx2j",
        "outputId": "9e489629-988a-4369-ab02-b070799f8a53"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "152XDmPEbzA2",
        "outputId": "610d295e-e249-43a5-a01f-a8e2a6349fb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3TNi8Z4baH0",
        "outputId": "de4bcc2b-2a43-4099-ca85-8290bbffb36e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                query    keyword\n",
            "0   How do I reset my password for the company por...      reset\n",
            "1   My computer is running slow; can it be upgrade...   computer\n",
            "2                                   applied for leave    applied\n",
            "3                                   applied for leave    applied\n",
            "4        How can I access company resources remotely?     access\n",
            "5                                   applied for leave    applied\n",
            "6   When is the last date for submitting travel or...       last\n",
            "7       I'm having issues with a software/application     issues\n",
            "8     What's the procedure to claim medical expenses?  procedure\n",
            "9   Can you explain the maternity/paternity leave ...    explain\n",
            "10        What is the process for applying for leave?    process\n",
            "11                      applied leave for second half    applied\n",
            "12  How can I update my personal information in th...     update\n",
            "13  How do I reset my password for the company por...      reset\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "# Load data with explicit encoding\n",
        "df = pd.read_csv('queries_for_nlp.csv', encoding='utf-8')\n",
        "\n",
        "# Preprocess text\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# Extract keywords using regular expressions\n",
        "def extract_keyword(text):\n",
        "    tokens = preprocess(text)\n",
        "    if tokens:\n",
        "        # Use regular expression to find a word with at least one alphabet character and no punctuation\n",
        "        keyword = next((word for word in tokens if re.match(r'^[a-zA-Z]+$', word)), None)\n",
        "        if keyword:\n",
        "            return keyword\n",
        "    return 'NoKeyword'\n",
        "\n",
        "df['keyword'] = df['query'].apply(extract_keyword)\n",
        "\n",
        "print(df[['query', 'keyword']])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "  tokens = word_tokenize(text.lower())\n",
        "  tokens = [t for t in tokens if t not in stop_words]\n",
        "  return tokens\n",
        "\n",
        "query = input(\"Enter the query: \")\n",
        "\n",
        "tokens = preprocess(query)\n",
        "keyword = sorted(set(tokens), key=tokens.count, reverse=True)[0]\n",
        "\n",
        "print(\"Keyword:\", keyword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klBDCLkkb3a5",
        "outputId": "857c9e8e-826a-4754-aea1-e5cd96ed4f77"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the query: i love my company\n",
            "Keyword: company\n"
          ]
        }
      ]
    }
  ]
}